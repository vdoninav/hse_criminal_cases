{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OahQlSkjgbCI",
        "outputId": "ceb84a5a-91b7-484e-a3f6-7febba7731f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# should have a directory with files from\n",
        "# https://drive.google.com/drive/folders/1g5H3LsgZnYdPhtZntYFI4eUzbnzdXULf\n",
        "# (save in TRAIN_PATH, TEST_PATH, VALIDATION_PATH in params.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjqrYrWPgT4r",
        "outputId": "24066271-c572-4075-c7a1-786a1657e8c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqpun3jKvFi5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets transformers seqeval\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate\n",
        "!pip install tensorrt\n",
        "!pip install tensorflow\n",
        "!pip install transformers[torch]\n",
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zuy7wBSrpezy",
        "outputId": "e4d1594e-e1b6-436b-ceea-6d4636cb0e28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'hse_criminal_cases'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 44 (delta 12), reused 34 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (44/44), 142.76 KiB | 1.10 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vdoninav/hse_criminal_cases.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXpt6itsr3W6",
        "outputId": "b05c79b2-a5cb-4b1c-8144-11a0e66ba7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/hse_criminal_cases/ner_run_files\n"
          ]
        }
      ],
      "source": [
        "%cd /content/hse_criminal_cases/ner_run_files/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljnBu_BDrg-P",
        "outputId": "89c29038-61e1-4228-811b-d36847f29b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/vdoninav/hse_criminal_cases\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "demIzxxwq2As"
      },
      "outputs": [],
      "source": [
        "!python preprocessing.py\n",
        "\n",
        "# if RENEW_SAVED_DATA_IN_PREPROCESSING and\n",
        "# should have a directory for saving tokenized data\n",
        "# (save in SAVE_DIR in params.py)\n",
        "\n",
        "# else\n",
        "# should have tokenized_train.pkl, tokenized_test.pkl, tokenized_validation.pkl in SAVE_DIR\n",
        "\n",
        "# if not CHOP_LONG_TEXTS\n",
        "# should have chopped_tokenized_train.pkl, chopped_tokenized_test.pkl, chopped_tokenized_validation.pkl in SAVE_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJzdt9YiqziH"
      },
      "outputs": [],
      "source": [
        "!python main.py\n",
        "\n",
        "# should have a directory for saving checkpoints\n",
        "# (save in CHECKPOINTS_DIR in params.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjY7uQ-NeAnk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
